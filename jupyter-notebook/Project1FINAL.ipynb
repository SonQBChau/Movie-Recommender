{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used code from this tutorial:\n",
    "# https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Collaborative%20Filtering%20Model%20with%20TensorFlow.ipynb\n",
    "# And we also used code from this tutorial:\n",
    "# https://medium.com/@connectwithghosh/recommender-system-on-the-movielens-using-an-autoencoder-using-tensorflow-in-python-f13d3e8d600d\n",
    "# Then, we integrated these two tutorials and edited the code from each of them in order to create a recommender that allows us to recommend a top 10 list of movies without needing to retrain for each new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.read_csv('/Users/blakemyers/Desktop/data/ratings.csv', error_bad_lines=False, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv(\"/Users/blakemyers/Desktop/data/movies.csv\", error_bad_lines=False, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating = pd.merge(rating, movie, on = 'movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie = movie_rating.groupby(\"title\")[\"rating\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie.rename({\"rating\": \"ratecount_movie\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie = numrate_movie.query(\"ratecount_movie >= 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings20plus = pd.merge(numrate_movie, movie_rating, on = 'title', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user = ratings20plus.groupby(\"userId\")[\"rating\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user.rename({\"rating\": \"ratecount_user\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user = numrate_user.query(\"ratecount_user >= 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus= pd.merge(ratings20plus, numrate_user, on = \"userId\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float)\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "ur20plus['rating'] = rating_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title'])\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "user_movie_matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(user_movie_matrix, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/blakemyers/opt/anaconda3/envs/tf_environment/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = ur20plus['title'].nunique()\n",
    "n_nodes_inpl = num_input  \n",
    "n_nodes_hl1  = 256  \n",
    "n_nodes_outl = num_input  \n",
    "hidden_1_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_inpl+1,n_nodes_hl1]))}\n",
    "output_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1+1,n_nodes_outl]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/blakemyers/opt/anaconda3/envs/tf_environment/lib/python3.7/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.placeholder('float', [None, num_input])\n",
    "input_layer_const = tf.fill( [tf.shape(input_layer)[0], 1] ,1.0  )\n",
    "input_layer_concat =  tf.concat([input_layer, input_layer_const], 1)\n",
    "layer_1 = tf.nn.sigmoid(tf.matmul(input_layer_concat,hidden_1_layer_vals['weights']))\n",
    "layer1_const = tf.fill( [tf.shape(layer_1)[0], 1] ,1.0  )\n",
    "layer_concat =  tf.concat([layer_1, layer1_const], 1)\n",
    "output_layer = tf.matmul( layer_concat,output_layer_vals['weights'])\n",
    "output_true = tf.placeholder('float', [None, num_input])\n",
    "meansq =    tf.reduce_mean(tf.square(output_layer - output_true))\n",
    "learn_rate = 0.1\n",
    "optimizer = tf.train.AdagradOptimizer(learn_rate).minimize(meansq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "batch_size = 100\n",
    "hm_epochs =200\n",
    "tot_images = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 92.15384025130686 MSE test 92.25354846383513\n",
      "Epoch 0 / 200 loss: 432.0061798095703\n",
      "MSE train 76.31214096557848 MSE test 76.65427949986173\n",
      "Epoch 1 / 200 loss: 343.7706985473633\n",
      "MSE train 66.05959931499925 MSE test 66.55124717812154\n",
      "Epoch 2 / 200 loss: 289.4535217285156\n",
      "MSE train 58.98704407057871 MSE test 59.610382379759415\n",
      "Epoch 3 / 200 loss: 253.53247451782227\n",
      "MSE train 53.843542091425654 MSE test 54.586492444895036\n",
      "Epoch 4 / 200 loss: 228.27988052368164\n",
      "MSE train 49.95654850558575 MSE test 50.80444097747289\n",
      "Epoch 5 / 200 loss: 209.66203689575195\n",
      "MSE train 46.931385344827135 MSE test 47.871373638953294\n",
      "Epoch 6 / 200 loss: 195.44293594360352\n",
      "MSE train 44.50912477506145 MSE test 45.536849648601255\n",
      "Epoch 7 / 200 loss: 184.2594757080078\n",
      "MSE train 42.52874443703037 MSE test 43.63714951309327\n",
      "Epoch 8 / 200 loss: 175.2269287109375\n",
      "MSE train 40.8770942531337 MSE test 42.059769029497765\n",
      "Epoch 9 / 200 loss: 167.78479385375977\n",
      "MSE train 39.47241282529057 MSE test 40.726455305060796\n",
      "Epoch 10 / 200 loss: 161.52851104736328\n",
      ".......................\n",
      "MSE train 4.527467460452865 MSE test 7.268997149241994\n",
      "Epoch 190 / 200 loss: 17.090697050094604\n",
      "MSE train 4.499161627829675 MSE test 7.237692087054816\n",
      "Epoch 191 / 200 loss: 16.977832555770874\n",
      "MSE train 4.471113063862072 MSE test 7.20679059323074\n",
      "Epoch 192 / 200 loss: 16.86594843864441\n",
      "MSE train 4.443326039662032 MSE test 7.176288825114897\n",
      "Epoch 193 / 200 loss: 16.75505232810974\n",
      "MSE train 4.415810008621967 MSE test 7.146182882019713\n",
      "Epoch 194 / 200 loss: 16.64517855644226\n",
      "MSE train 4.388578582704203 MSE test 7.116469689184084\n",
      "Epoch 195 / 200 loss: 16.536377906799316\n",
      "MSE train 4.361648286601421 MSE test 7.087145652432658\n",
      "Epoch 196 / 200 loss: 16.42871880531311\n",
      "MSE train 4.335038286942148 MSE test 7.0582073490893045\n",
      "Epoch 197 / 200 loss: 16.322283506393433\n",
      "MSE train 4.308768760027254 MSE test 7.029650404517632\n",
      "Epoch 198 / 200 loss: 16.21716070175171\n",
      "MSE train 4.282856774331374 MSE test 7.001469002397052\n",
      "Epoch 199 / 200 loss: 16.11344265937805\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(hm_epochs):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i in range(int(tot_images/batch_size)):\n",
    "        epoch_x = X_train[ i*batch_size : (i+1)*batch_size ]\n",
    "        _, c = sess.run([optimizer, meansq],\\\n",
    "               feed_dict={input_layer: epoch_x, \\\n",
    "               output_true: epoch_x})\n",
    "        epoch_loss += c\n",
    "        \n",
    "    output_train = sess.run(output_layer,\\\n",
    "               feed_dict={input_layer:X_train})\n",
    "    output_test = sess.run(output_layer,\\\n",
    "                   feed_dict={input_layer:X_test})\n",
    "        \n",
    "    if epoch <= 10 or epoch >= 190:\n",
    "        print('MSE train', MSE(output_train, X_train),'MSE test', MSE(output_test, X_test))\n",
    "        print('Epoch', epoch, '/', hm_epochs, 'loss:',epoch_loss)\n",
    "    elif epoch == 11:\n",
    "        print('.......................')\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Goodfellas (1990)',\n",
       " 'Silence of the Lambs, The (1991)',\n",
       " 'Streetcar Named Desire, A (1951)',\n",
       " 'Finding Nemo (2003)',\n",
       " 'Darjeeling Limited, The (2007)',\n",
       " \"Bridget Jones's Diary (2001)\",\n",
       " 'Final Destination (2000)',\n",
       " 'Fish Called Wanda, A (1988)',\n",
       " 'Chinatown (1974)',\n",
       " 'Clerks (1994)']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieve the top 10 recommendations for a new user who rated one movie, i.e., \"Aliens (1986)\", with a 5/5.\n",
    "userCol = ur20plus[\"userId\"]\n",
    "max_value = userCol.max()\n",
    "new_userId = max_value + 1\n",
    "ur20plus= pd.merge(ratings20plus, numrate_user, on = \"userId\", how = \"inner\")\n",
    "ur20plus = ur20plus.append(pd.DataFrame([[\"Aliens (1986)\",1,new_userId,4370,5,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)\n",
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float)\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "ur20plus['rating'] = rating_scaled\n",
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title'])\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "user_movie_matrix.fillna(0, inplace=True)\n",
    "pred_data = pd.DataFrame()\n",
    "preds = sess.run(output_layer, feed_dict={input_layer: user_movie_matrix})\n",
    "pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "pred_data = pred_data.stack().reset_index(name='rating')\n",
    "pred_data.columns = ['userId', 'title', 'rating']\n",
    "users = user_movie_matrix.index.tolist()\n",
    "movies = user_movie_matrix.columns.tolist()\n",
    "pred_data['userId'] = pred_data['userId'].map(lambda value: users[value])\n",
    "pred_data['title'] = pred_data['title'].map(lambda value: movies[value])\n",
    "keys = ['userId', 'title']\n",
    "index_1 = pred_data.set_index(keys).index\n",
    "index_2 = ur20plus.set_index(keys).index\n",
    "top_ten_ranked = pred_data[~index_1.isin(index_2)]\n",
    "top_ten_ranked = top_ten_ranked.sort_values(['userId', 'rating'], ascending=[True, False])\n",
    "top_ten_ranked = top_ten_ranked.groupby('userId').head(10)\n",
    "list(top_ten_ranked.loc[top_ten_ranked['userId'] == new_userId]['title'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Goodfellas (1990)',\n",
       " 'Midnight in Paris (2011)',\n",
       " 'Streetcar Named Desire, A (1951)',\n",
       " 'Prestige, The (2006)',\n",
       " 'Jurassic Park (1993)',\n",
       " 'Fish Called Wanda, A (1988)',\n",
       " 'Quiz Show (1994)',\n",
       " 'October Sky (1999)',\n",
       " 'Amadeus (1984)',\n",
       " 'Deep Blue Sea (1999)']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieve the top 10 recommendations for a new user who rated one movie, i.e., \"(500) Days of Summer (2009)\", with a 5/5.\n",
    "userCol = ur20plus[\"userId\"]\n",
    "max_value = userCol.max()\n",
    "new_userId = max_value + 1\n",
    "ur20plus= pd.merge(ratings20plus, numrate_user, on = \"userId\", how = \"inner\")\n",
    "ur20plus = ur20plus.append(pd.DataFrame([[\"(500) Days of Summer (2009)\",1,new_userId,4370,3,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)\n",
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float)\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "ur20plus['rating'] = rating_scaled\n",
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title'])\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "user_movie_matrix.fillna(0, inplace=True)\n",
    "pred_data = pd.DataFrame()\n",
    "preds = sess.run(output_layer, feed_dict={input_layer: user_movie_matrix})\n",
    "pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "pred_data = pred_data.stack().reset_index(name='rating')\n",
    "pred_data.columns = ['userId', 'title', 'rating']\n",
    "users = user_movie_matrix.index.tolist()\n",
    "movies = user_movie_matrix.columns.tolist()\n",
    "pred_data['userId'] = pred_data['userId'].map(lambda value: users[value])\n",
    "pred_data['title'] = pred_data['title'].map(lambda value: movies[value])\n",
    "keys = ['userId', 'title']\n",
    "index_1 = pred_data.set_index(keys).index\n",
    "index_2 = ur20plus.set_index(keys).index\n",
    "top_ten_ranked = pred_data[~index_1.isin(index_2)]\n",
    "top_ten_ranked = top_ten_ranked.sort_values(['userId', 'rating'], ascending=[True, False])\n",
    "top_ten_ranked = top_ten_ranked.groupby('userId').head(10)\n",
    "list(top_ten_ranked.loc[top_ten_ranked['userId'] == new_userId]['title'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
