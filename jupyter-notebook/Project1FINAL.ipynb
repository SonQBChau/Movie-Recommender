{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used code from this tutorial:\n",
    "# https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Collaborative%20Filtering%20Model%20with%20TensorFlow.ipynb\n",
    "# And we also used code from this tutorial:\n",
    "# https://medium.com/@connectwithghosh/recommender-system-on-the-movielens-using-an-autoencoder-using-tensorflow-in-python-f13d3e8d600d\n",
    "# Then, we integrated these two tutorials and edited the code from each of them in order to create a recommender that allows us to recommend a top 10 list of movies without needing to retrain for each new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.read_csv('/Users/blakemyers/Desktop/data/ratings.csv', error_bad_lines=False, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv(\"/Users/blakemyers/Desktop/data/movies.csv\", error_bad_lines=False, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating = pd.merge(rating, movie, on = 'movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie = movie_rating.groupby(\"title\")[\"rating\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie.rename({\"rating\": \"ratecount_movie\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie = numrate_movie.query(\"ratecount_movie >= 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings20plus = pd.merge(numrate_movie, movie_rating, on = 'title', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user = ratings20plus.groupby(\"userId\")[\"rating\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user.rename({\"rating\": \"ratecount_user\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user = numrate_user.query(\"ratecount_user >= 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus= pd.merge(ratings20plus, numrate_user, on = \"userId\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float)\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "ur20plus['rating'] = rating_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title'])\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "user_movie_matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(user_movie_matrix, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/blakemyers/opt/anaconda3/envs/tf_environment/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = ur20plus['title'].nunique()\n",
    "n_nodes_inpl = num_input  \n",
    "n_nodes_hl1  = 256  \n",
    "n_nodes_outl = num_input  \n",
    "hidden_1_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_inpl+1,n_nodes_hl1]))}\n",
    "output_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1+1,n_nodes_outl]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/blakemyers/opt/anaconda3/envs/tf_environment/lib/python3.7/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.placeholder('float', [None, num_input])\n",
    "input_layer_const = tf.fill( [tf.shape(input_layer)[0], 1] ,1.0  )\n",
    "input_layer_concat =  tf.concat([input_layer, input_layer_const], 1)\n",
    "layer_1 = tf.nn.sigmoid(tf.matmul(input_layer_concat,hidden_1_layer_vals['weights']))\n",
    "layer1_const = tf.fill( [tf.shape(layer_1)[0], 1] ,1.0  )\n",
    "layer_concat =  tf.concat([layer_1, layer1_const], 1)\n",
    "output_layer = tf.matmul( layer_concat,output_layer_vals['weights'])\n",
    "output_true = tf.placeholder('float', [None, num_input])\n",
    "meansq =    tf.reduce_mean(tf.square(output_layer - output_true))\n",
    "learn_rate = 0.1\n",
    "optimizer = tf.train.AdagradOptimizer(learn_rate).minimize(meansq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "batch_size = 100\n",
    "hm_epochs =200\n",
    "tot_images = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 85.26557522124689 MSE test 85.32654965854096\n",
      "Epoch 0 / 200 loss: 392.18053436279297\n",
      "MSE train 71.84931197075936 MSE test 71.96227213184854\n",
      "Epoch 1 / 200 loss: 319.0783920288086\n",
      "MSE train 62.867976500428036 MSE test 63.02341941149882\n",
      "Epoch 2 / 200 loss: 272.68739318847656\n",
      "MSE train 56.528467517934594 MSE test 56.72587973875652\n",
      "Epoch 3 / 200 loss: 241.0486946105957\n",
      "MSE train 51.82830375493313 MSE test 52.09616366664766\n",
      "Epoch 4 / 200 loss: 218.34769821166992\n",
      "MSE train 48.205318933451856 MSE test 48.574907126192606\n",
      "Epoch 5 / 200 loss: 201.27299880981445\n",
      "MSE train 45.34290346301186 MSE test 45.818046594924716\n",
      "Epoch 6 / 200 loss: 187.97752380371094\n",
      "MSE train 43.02655303050838 MSE test 43.60500727810276\n",
      "Epoch 7 / 200 loss: 177.3773651123047\n",
      "MSE train 41.120503684459464 MSE test 41.79050338061943\n",
      "Epoch 8 / 200 loss: 168.72731399536133\n",
      "MSE train 39.53200104395983 MSE test 40.27699722727292\n",
      "Epoch 9 / 200 loss: 161.570556640625\n",
      "MSE train 38.187229356908595 MSE test 38.993875042200095\n",
      "Epoch 10 / 200 loss: 155.57213592529297\n",
      ".......................\n",
      "MSE train 5.500362685643401 MSE test 7.390518827383494\n",
      "Epoch 190 / 200 loss: 21.077048778533936\n",
      "MSE train 5.465573030081852 MSE test 7.353792085450526\n",
      "Epoch 191 / 200 loss: 20.93735122680664\n",
      "MSE train 5.431198033919336 MSE test 7.317471718618627\n",
      "Epoch 192 / 200 loss: 20.79956865310669\n",
      "MSE train 5.397157893849538 MSE test 7.281494222297927\n",
      "Epoch 193 / 200 loss: 20.663341522216797\n",
      "MSE train 5.363398525953847 MSE test 7.245817396659917\n",
      "Epoch 194 / 200 loss: 20.52838706970215\n",
      "MSE train 5.329925480886295 MSE test 7.210442625833167\n",
      "Epoch 195 / 200 loss: 20.394547939300537\n",
      "MSE train 5.296833137921236 MSE test 7.175440609453423\n",
      "Epoch 196 / 200 loss: 20.261947631835938\n",
      "MSE train 5.2642431106163805 MSE test 7.140924425316784\n",
      "Epoch 197 / 200 loss: 20.13102388381958\n",
      "MSE train 5.232203182390091 MSE test 7.106968386885233\n",
      "Epoch 198 / 200 loss: 20.002204418182373\n",
      "MSE train 5.20070625659355 MSE test 7.07359354368647\n",
      "Epoch 199 / 200 loss: 19.875587463378906\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(hm_epochs):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i in range(int(tot_images/batch_size)):\n",
    "        epoch_x = X_train[ i*batch_size : (i+1)*batch_size ]\n",
    "        _, c = sess.run([optimizer, meansq],\\\n",
    "               feed_dict={input_layer: epoch_x, \\\n",
    "               output_true: epoch_x})\n",
    "        epoch_loss += c\n",
    "        \n",
    "    output_train = sess.run(output_layer,\\\n",
    "               feed_dict={input_layer:X_train})\n",
    "    output_test = sess.run(output_layer,\\\n",
    "                   feed_dict={input_layer:X_test})\n",
    "        \n",
    "    if epoch <= 10 or epoch >= 190:\n",
    "        print('MSE train', MSE(output_train, X_train),'MSE test', MSE(output_test, X_test))\n",
    "        print('Epoch', epoch, '/', hm_epochs, 'loss:',epoch_loss)\n",
    "    elif epoch == 11:\n",
    "        print('.......................')\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drive (2011)',\n",
       " 'Hudsucker Proxy, The (1994)',\n",
       " 'Omen, The (1976)',\n",
       " 'Tombstone (1993)',\n",
       " 'Cool Runnings (1993)',\n",
       " 'Splash (1984)',\n",
       " 'Grifters, The (1990)',\n",
       " 'Traffic (2000)',\n",
       " 'Fighter, The (2010)',\n",
       " 'Fish Called Wanda, A (1988)']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieve the top 10 recommendations for a new user who rated one movie, i.e., \"Aliens (1986)\", with a 5/5.\n",
    "userCol = ur20plus[\"userId\"]\n",
    "max_value = userCol.max()\n",
    "new_userId = max_value + 1\n",
    "ur20plus= pd.merge(ratings20plus, numrate_user, on = \"userId\", how = \"inner\")\n",
    "ur20plus = ur20plus.append(pd.DataFrame([[\"Aliens (1986)\",1,new_userId,1,5,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)\n",
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float)\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "ur20plus['rating'] = rating_scaled\n",
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title'])\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "user_movie_matrix.fillna(0, inplace=True)\n",
    "pred_data = pd.DataFrame()\n",
    "preds = sess.run(output_layer, feed_dict={input_layer: user_movie_matrix})\n",
    "pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "pred_data = pred_data.stack().reset_index(name='rating')\n",
    "pred_data.columns = ['userId', 'title', 'rating']\n",
    "users = user_movie_matrix.index.tolist()\n",
    "movies = user_movie_matrix.columns.tolist()\n",
    "pred_data['userId'] = pred_data['userId'].map(lambda value: users[value])\n",
    "pred_data['title'] = pred_data['title'].map(lambda value: movies[value])\n",
    "keys = ['userId', 'title']\n",
    "index_1 = pred_data.set_index(keys).index\n",
    "index_2 = ur20plus.set_index(keys).index\n",
    "top_ten_ranked = pred_data[~index_1.isin(index_2)]\n",
    "top_ten_ranked = top_ten_ranked.sort_values(['userId', 'rating'], ascending=[True, False])\n",
    "top_ten_ranked = top_ten_ranked.groupby('userId').head(10)\n",
    "list(top_ten_ranked.loc[top_ten_ranked['userId'] == new_userId]['title'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eXistenZ (1999)',\n",
       " \"Singin' in the Rain (1952)\",\n",
       " 'Mystery Men (1999)',\n",
       " 'Departed, The (2006)',\n",
       " 'Like Water for Chocolate (Como agua para chocolate) (1992)',\n",
       " 'Big Trouble in Little China (1986)',\n",
       " 'Splash (1984)',\n",
       " 'Close Encounters of the Third Kind (1977)',\n",
       " 'Star Wars: Episode I - The Phantom Menace (1999)',\n",
       " 'Young Frankenstein (1974)']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieve the top 10 recommendations for a new user who rated one movie, i.e., \"(500) Days of Summer (2009)\", with a 3/5.\n",
    "userCol = ur20plus[\"userId\"]\n",
    "max_value = userCol.max()\n",
    "new_userId = max_value + 1\n",
    "ur20plus= pd.merge(ratings20plus, numrate_user, on = \"userId\", how = \"inner\")\n",
    "ur20plus = ur20plus.append(pd.DataFrame([[\"(500) Days of Summer (2009)\",1,new_userId,1,3,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)\n",
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float)\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "ur20plus['rating'] = rating_scaled\n",
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title'])\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "user_movie_matrix.fillna(0, inplace=True)\n",
    "pred_data = pd.DataFrame()\n",
    "preds = sess.run(output_layer, feed_dict={input_layer: user_movie_matrix})\n",
    "pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "pred_data = pred_data.stack().reset_index(name='rating')\n",
    "pred_data.columns = ['userId', 'title', 'rating']\n",
    "users = user_movie_matrix.index.tolist()\n",
    "movies = user_movie_matrix.columns.tolist()\n",
    "pred_data['userId'] = pred_data['userId'].map(lambda value: users[value])\n",
    "pred_data['title'] = pred_data['title'].map(lambda value: movies[value])\n",
    "keys = ['userId', 'title']\n",
    "index_1 = pred_data.set_index(keys).index\n",
    "index_2 = ur20plus.set_index(keys).index\n",
    "top_ten_ranked = pred_data[~index_1.isin(index_2)]\n",
    "top_ten_ranked = top_ten_ranked.sort_values(['userId', 'rating'], ascending=[True, False])\n",
    "top_ten_ranked = top_ten_ranked.groupby('userId').head(10)\n",
    "list(top_ten_ranked.loc[top_ten_ranked['userId'] == new_userId]['title'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
