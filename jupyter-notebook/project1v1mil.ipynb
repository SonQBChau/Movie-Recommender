{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used code from this tutorial:\n",
    "# https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Collaborative%20Filtering%20Model%20with%20TensorFlow.ipynb\n",
    "# And we also used code from this tutorial:\n",
    "# https://medium.com/@connectwithghosh/recommender-system-on-the-movielens-using-an-autoencoder-using-tensorflow-in-python-f13d3e8d600d\n",
    "# Then, we integrated these two tutorials and edited the code from each of them in order to create a recommender that allows us to recommend a top 10 list of movies without needing to retrain for each new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.read_csv('big_data/ratings.csv', sep = \"::\", error_bad_lines=False, encoding='latin-1', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating.rename({\"1\": \"userId\", \"1193\": \"movieId\", \"5\": \"rating\", \"978300760\": \"timestamp\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv(\"big_data/movies.csv\", sep = \"::\", error_bad_lines=False, encoding='latin-1', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.rename({\"1\": \"movieId\", \"Toy Story (1995)\": \"title\", \"Animation|Children's|Comedy\": \"genre\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating = pd.merge(rating, movie, on = 'movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie = movie_rating.groupby(\"title\")[\"rating\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie.rename({\"rating\": \"ratecount_movie\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_movie = numrate_movie.query(\"ratecount_movie >= 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings20plus = pd.merge(numrate_movie, movie_rating, on = 'title', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user = ratings20plus.groupby(\"userId\")[\"rating\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user.rename({\"rating\": \"ratecount_user\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrate_user = numrate_user.query(\"ratecount_user >= 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = pd.merge(ratings20plus, numrate_user, on = \"userId\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float) #set rating values as float\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "#place the rating values on a scale from -1 to 1\n",
    "ur20plus['rating'] = rating_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title']) #drop duplicates\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "#create matrix (see below)\n",
    "user_movie_matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(user_movie_matrix, train_size=0.8)\n",
    "#split the training data (80%) from the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Son\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = ur20plus['title'].nunique()\n",
    "# Deciding how many nodes each layer should have\n",
    "n_nodes_inpl = num_input\n",
    "n_nodes_hl1  = 256\n",
    "n_nodes_outl = num_input  \n",
    "# first hidden layer has num_input*32 weights and 32 biases\n",
    "hidden_1_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_inpl+1,n_nodes_hl1]))}\n",
    "# first hidden layer has 784*32 weights and 32 biases\n",
    "output_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1+1,n_nodes_outl]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Son\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow_core\\python\\training\\adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.placeholder('float', [None, num_input])\n",
    "# add a constant node to the first layer\n",
    "# it needs to have the same shape as the input layer to be able to concatinate it later\n",
    "input_layer_const = tf.fill( [tf.shape(input_layer)[0], 1] ,1.0  )\n",
    "input_layer_concat =  tf.concat([input_layer, input_layer_const], 1)\n",
    "# multiply output of input_layer wth a weight matrix \n",
    "layer_1 = tf.nn.sigmoid(tf.matmul(input_layer_concat,\\\n",
    "hidden_1_layer_vals['weights']))\n",
    "# adding one bias node to the hidden layer\n",
    "layer1_const = tf.fill( [tf.shape(layer_1)[0], 1] ,1.0  )\n",
    "layer_concat =  tf.concat([layer_1, layer1_const], 1)\n",
    "# multiply output of hidden with a weight matrix to get final output\n",
    "output_layer = tf.matmul( layer_concat,output_layer_vals['weights'])\n",
    "# output_true shall have the original shape for error calculations\n",
    "output_true = tf.placeholder('float', [None, num_input])\n",
    "# define cost function\n",
    "meansq =    tf.reduce_mean(tf.square(output_layer - output_true))\n",
    "# define optimizer\n",
    "learn_rate = 0.1   # how fast the model should learn\n",
    "optimizer = tf.train.AdagradOptimizer(learn_rate).minimize(meansq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising variables and starting the session\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "# defining batch size, number of epochs and learning rate\n",
    "batch_size = 100  # how many images to use together for training\n",
    "hm_epochs =200    # how many times to go through the entire dataset\n",
    "tot_images = X_train.shape[0] # total number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 46.380179793167535 MSE test 46.672074497196505\n",
      "Epoch 0 / 200 loss: 3301.287986755371\n",
      "MSE train 30.904770200256028 MSE test 31.105200648208758\n",
      "Epoch 1 / 200 loss: 1819.0695171356201\n",
      "MSE train 22.309516237515027 MSE test 22.48869904320725\n",
      "Epoch 2 / 200 loss: 1268.3550605773926\n",
      "MSE train 16.831422192343634 MSE test 16.94413875880739\n",
      "Epoch 3 / 200 loss: 935.2982873916626\n",
      "MSE train 13.181665714983968 MSE test 13.31123114869411\n",
      "Epoch 4 / 200 loss: 718.2910089492798\n",
      "MSE train 10.799190714793072 MSE test 10.939400832763225\n",
      "Epoch 5 / 200 loss: 574.7171277999878\n",
      "MSE train 9.150585528615292 MSE test 9.283602543038224\n",
      "Epoch 6 / 200 loss: 478.8486623764038\n",
      "MSE train 7.95469703292151 MSE test 8.079505713872148\n",
      "Epoch 7 / 200 loss: 411.0414843559265\n",
      "MSE train 7.039133074376187 MSE test 7.159159045794751\n",
      "Epoch 8 / 200 loss: 360.5341911315918\n",
      "MSE train 6.318384890399996 MSE test 6.43394682044787\n",
      "Epoch 9 / 200 loss: 321.3250422477722\n",
      "MSE train 5.734630749832954 MSE test 5.84617739570224\n",
      "Epoch 10 / 200 loss: 290.0360550880432\n",
      ".......................\n",
      "MSE train 0.18667014045864042 MSE test 0.3349859068972089\n",
      "Epoch 190 / 200 loss: 9.02572787553072\n",
      "MSE train 0.18510126462097895 MSE test 0.3333652249578208\n",
      "Epoch 191 / 200 loss: 8.949672907590866\n",
      "MSE train 0.18355426625343607 MSE test 0.33176661494748466\n",
      "Epoch 192 / 200 loss: 8.874675326049328\n",
      "MSE train 0.18202892599465542 MSE test 0.33018970043359097\n",
      "Epoch 193 / 200 loss: 8.800721235573292\n",
      "MSE train 0.18052507757408254 MSE test 0.32863411607673637\n",
      "Epoch 194 / 200 loss: 8.72780104726553\n",
      "MSE train 0.1790426182618838 MSE test 0.32709952313834123\n",
      "Epoch 195 / 200 loss: 8.655906975269318\n",
      "MSE train 0.17758146456974952 MSE test 0.3255856146783381\n",
      "Epoch 196 / 200 loss: 8.585034012794495\n",
      "MSE train 0.17614153384455253 MSE test 0.3240920428682226\n",
      "Epoch 197 / 200 loss: 8.515178509056568\n",
      "MSE train 0.17472270946092402 MSE test 0.32261846450134524\n",
      "Epoch 198 / 200 loss: 8.446335904300213\n",
      "MSE train 0.17332484875139456 MSE test 0.3211645800825059\n",
      "Epoch 199 / 200 loss: 8.378501631319523\n"
     ]
    }
   ],
   "source": [
    "# running the model for a 200 epochs taking 100 users in batches\n",
    "# total improvement is printed out after each epoch\n",
    "for epoch in range(hm_epochs):\n",
    "    epoch_loss = 0    # initializing loss (error) as 0\n",
    "    \n",
    "    for i in range(int(tot_images/batch_size)):\n",
    "        epoch_x = X_train[ i*batch_size : (i+1)*batch_size ]\n",
    "        _, c = sess.run([optimizer, meansq],\\\n",
    "               feed_dict={input_layer: epoch_x, \\\n",
    "               output_true: epoch_x})\n",
    "        epoch_loss += c\n",
    "        \n",
    "    output_train = sess.run(output_layer,\\\n",
    "               feed_dict={input_layer:X_train})\n",
    "    output_test = sess.run(output_layer,\\\n",
    "                   feed_dict={input_layer:X_test})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18300256</th>\n",
       "      <td>6041</td>\n",
       "      <td>Story of G.I. Joe, The (1945)</td>\n",
       "      <td>2.522219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18298416</th>\n",
       "      <td>6041</td>\n",
       "      <td>Dog Park (1998)</td>\n",
       "      <td>2.341502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18298077</th>\n",
       "      <td>6041</td>\n",
       "      <td>Broadway Melody, The (1929)</td>\n",
       "      <td>2.334806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18299844</th>\n",
       "      <td>6041</td>\n",
       "      <td>Professional, The (a.k.a. Leon: The Profession...</td>\n",
       "      <td>2.283562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18299467</th>\n",
       "      <td>6041</td>\n",
       "      <td>Mr. Death: The Rise and Fall of Fred A. Leucht...</td>\n",
       "      <td>2.281995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18300148</th>\n",
       "      <td>6041</td>\n",
       "      <td>Smoke (1995)</td>\n",
       "      <td>2.261795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18300435</th>\n",
       "      <td>6041</td>\n",
       "      <td>Toxic Avenger, The (1985)</td>\n",
       "      <td>2.220790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18299436</th>\n",
       "      <td>6041</td>\n",
       "      <td>Misérables, Les (1995)</td>\n",
       "      <td>2.210887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18299482</th>\n",
       "      <td>6041</td>\n",
       "      <td>Mrs. Parker and the Vicious Circle (1994)</td>\n",
       "      <td>2.175649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18298689</th>\n",
       "      <td>6041</td>\n",
       "      <td>From the Hip (1987)</td>\n",
       "      <td>2.110963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId                                              title    rating\n",
       "18300256    6041                      Story of G.I. Joe, The (1945)  2.522219\n",
       "18298416    6041                                    Dog Park (1998)  2.341502\n",
       "18298077    6041                        Broadway Melody, The (1929)  2.334806\n",
       "18299844    6041  Professional, The (a.k.a. Leon: The Profession...  2.283562\n",
       "18299467    6041  Mr. Death: The Rise and Fall of Fred A. Leucht...  2.281995\n",
       "18300148    6041                                       Smoke (1995)  2.261795\n",
       "18300435    6041                          Toxic Avenger, The (1985)  2.220790\n",
       "18299436    6041                             Misérables, Les (1995)  2.210887\n",
       "18299482    6041          Mrs. Parker and the Vicious Circle (1994)  2.175649\n",
       "18298689    6041                                From the Hip (1987)  2.110963"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18301239</th>\n",
       "      <td>6042</td>\n",
       "      <td>Citizen Ruth (1996)</td>\n",
       "      <td>3.035116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18301616</th>\n",
       "      <td>6042</td>\n",
       "      <td>Favor, The (1994)</td>\n",
       "      <td>2.532531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18301905</th>\n",
       "      <td>6042</td>\n",
       "      <td>Hard Day's Night, A (1964)</td>\n",
       "      <td>2.528854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18301709</th>\n",
       "      <td>6042</td>\n",
       "      <td>French Kiss (1995)</td>\n",
       "      <td>2.450675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18301409</th>\n",
       "      <td>6042</td>\n",
       "      <td>Deconstructing Harry (1997)</td>\n",
       "      <td>2.422072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18301743</th>\n",
       "      <td>6042</td>\n",
       "      <td>G.I. Jane (1997)</td>\n",
       "      <td>2.402671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18301064</th>\n",
       "      <td>6042</td>\n",
       "      <td>Boiler Room (2000)</td>\n",
       "      <td>2.402489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18302361</th>\n",
       "      <td>6042</td>\n",
       "      <td>Maltese Falcon, The (1941)</td>\n",
       "      <td>2.380704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18302033</th>\n",
       "      <td>6042</td>\n",
       "      <td>I Know What You Did Last Summer (1997)</td>\n",
       "      <td>2.344082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18302660</th>\n",
       "      <td>6042</td>\n",
       "      <td>Nothing to Lose (1994)</td>\n",
       "      <td>2.333413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId                                   title    rating\n",
       "18301239    6042                     Citizen Ruth (1996)  3.035116\n",
       "18301616    6042                       Favor, The (1994)  2.532531\n",
       "18301905    6042              Hard Day's Night, A (1964)  2.528854\n",
       "18301709    6042                      French Kiss (1995)  2.450675\n",
       "18301409    6042             Deconstructing Harry (1997)  2.422072\n",
       "18301743    6042                        G.I. Jane (1997)  2.402671\n",
       "18301064    6042                      Boiler Room (2000)  2.402489\n",
       "18302361    6042              Maltese Falcon, The (1941)  2.380704\n",
       "18302033    6042  I Know What You Did Last Summer (1997)  2.344082\n",
       "18302660    6042                  Nothing to Lose (1994)  2.333413"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POST /get_recommended\n",
    "req = json.loads(REQUEST)\n",
    "movie_name = req['body']['movie'][0]\n",
    "movie_rating = req['body']['rating'][0]\n",
    "\n",
    "# a top 10 ranking for a new user (9999992) who rates \"Hurricane, The (1999)\" with a 3\n",
    "userCol = ur20plus[\"userId\"]\n",
    "max_value = userCol.max()\n",
    "new_userId = max_value + 1\n",
    "ur20plus = ur20plus.append(pd.DataFrame([[movie_name,1,new_userId,1,movie_rating,\"genre\",1]], columns =ur20plus.columns), ignore_index=True)\n",
    "scaler = MinMaxScaler()\n",
    "ur20plus['rating'] = ur20plus['rating'].values.astype(float)\n",
    "rating_scaled = pd.DataFrame(scaler.fit_transform(ur20plus['rating'].values.reshape(-1,1)))\n",
    "ur20plus['rating'] = rating_scaled\n",
    "ur20plus = ur20plus.drop_duplicates(['userId', 'title'])\n",
    "user_movie_matrix = ur20plus.pivot(index='userId', columns='title', values='rating')\n",
    "user_movie_matrix.fillna(0, inplace=True)\n",
    "pred_data = pd.DataFrame()\n",
    "preds = sess.run(output_layer, feed_dict={input_layer: user_movie_matrix})\n",
    "pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "pred_data = pred_data.stack().reset_index(name='rating')\n",
    "pred_data.columns = ['userId', 'title', 'rating']\n",
    "users = user_movie_matrix.index.tolist()\n",
    "movies = user_movie_matrix.columns.tolist()\n",
    "pred_data['userId'] = pred_data['userId'].map(lambda value: users[value])\n",
    "pred_data['title'] = pred_data['title'].map(lambda value: movies[value])\n",
    "keys = ['userId', 'title']\n",
    "index_1 = pred_data.set_index(keys).index\n",
    "index_2 = ur20plus.set_index(keys).index\n",
    "top_ten_ranked = pred_data[~index_1.isin(index_2)]\n",
    "top_ten_ranked = top_ten_ranked.sort_values(['userId', 'rating'], ascending=[True, False])\n",
    "top_ten_ranked = top_ten_ranked.groupby('userId').head(10)\n",
    "top_ten_ranked.loc[top_ten_ranked['userId'] == new_userId]\n",
    "print(top_ten_ranked.loc[top_ten_ranked['userId'] == new_userId])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [userId, title, rating]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
